---
title: 准确率(Accuracy)、精确率(Precision)、召回率(Recall)、P-R曲线
date: 2019-03-06 19:40:27
tags:
- 机器学习原理推导
categories:
- 机器学习原理推导
mathjax: true
---

# 算法预测结果的四种情况
正确肯定(真正例，True Positive,TP):预测为真，实际为真；
正确否定(真反例，True Negative,TN):预测为假，实际为假；
错误肯定(假正例，False Positive,FP):预测为真，实际为假 ；
错误否定(假反例，False Negative,FN):预测为假，实际为真。

样例总数为:TP+FP+TN+FN。
# 准确率(Accuracy)/精确率(Precision)/召回率(Recall)
**准确率:**
所有的预测正确(正类负类)的占总样本比重。
$$
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
$$
准确率指标存在明显的缺陷。当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。
**精确率:**
即正确预测为真的占全部预测为真的比例，即"找得对"。
$$
Precision=\frac{TP}{TP+FP}
$$
**召回率:**
正确预测为真的占全部实际为真的比例，即"找得全"。
$$
Recall=\frac{T P}{T P+F N}
$$
**F1-Score:**
精准率和召回率的调和平均值。
$$
\mathrm{Fl}=\frac{2\times \text {precision} \times \text {recall}}{\text {precision}+\text {recall}}=\frac{2 T P}{2 T P+F P+F N}
$$
# P-R曲线、精确率与召回率的关系
精确率和召回率是一对矛盾的度量。一般来说，精确率高时，召回率往往偏低；而召回率高时，精确率往往偏低,可以通过Precision-Recall图来取两者的平衡值。"平衡点"是"精确率=召回率"时的取值。
若一个学习器P-R曲线被另一个学习器的P-R曲线完全"包住",则可断言后者的性能优于前者。如果两个学习器的P-R曲线发生了交叉，如图中的A与B，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线截面积的大小，面积大者性能更优。
**举例:**
Hulu提供视频的模糊搜索功能，搜索排序模型返回的Top5的精确率非常高，但在实际使用过程中，用户还是经常找不到想要的视频，特别是一些比较冷门的剧集，这可能是哪个环节出了问题呢？
**在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N个返回结果的Precision值和Recall值来衡量排序模型的性能，即认为模型返回的Top N的结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision TOPN和前N个位置上的召回率Recall TOPN。**
为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致Recall值降低。
在上面这个例子中，模型返回的Precision TOP5的结果非常好，也就是说排序模型Top5的返回值的质量是很高的。也就是说前5个结果精确率很高。
但是在实际应用过程中，用户为了找一些冷门的视频，往往会寻找排在较靠后位置的结果，甚至翻页去查找目标视频。但根据题目描述，用户经常找不到想要的视频，这说明模型没有把相关的视频都找出来呈现给用户。显然，问题出在召回率上。如果相关结果有100个，即使Precision@5达到了100%，Recall@5也仅仅是5%。
这个时候我们就要用Precision-Recall曲线图。对于上面举例的排序模型来说，其P-R曲线上的一个点代表着在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。我们必须根据我们排序系统的主要任务(保证用户前5个结果为真？或保证用户找冷门视频的精确率?)从Precision-Recall曲线图找出一个平衡精确率和准确率的点，使得两者都能有较好的性能。