---
title: 准确率、精确率、召回率、P-R曲线
date: 2019-03-06 19:40:27
tags:
- 机器学习原理推导
categories:
- 机器学习原理推导
mathjax: true
---

# 算法预测结果的四种情况
正确肯定（真正例，True Positive,TP）：预测为真，实际为真；
正确否定（真反例，True Negative,TN）：预测为假，实际为假；
错误肯定（假正例，False Positive,FP）：预测为真，实际为假 ；
错误否定（假反例，False Negative,FN）：预测为假，实际为真。

样例总数为:TP+FP+TN+FN。
# 准确率（Accuracy）/精确率（Precision）/召回率（Recall）/F1 score与Fβ
**准确率:**
所有的预测正确（正类负类）的占总样本比重。
$$
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
$$
准确率指标存在明显的缺陷。当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。
**精确率:**
即正确预测为真的占全部预测为真的比例，即"找得对"。
$$
Precision=\frac{TP}{TP+FP}
$$
**召回率:**
正确预测为真的占全部实际为真的比例，即"找得全"。
$$
Recall=\frac{T P}{T P+F N}
$$
**F1-Score:**
精准率和召回率的调和平均值。
$$
\mathrm{Fl}=\frac{2\times \text {precision} \times \text {recall}}{\text {precision}+\text {recall}}=\frac{2 T P}{2 T P+F P+F N}
$$
**更一般地，我们可以定义Fβ（precision和recall权重可调的F1 score）:**
$$
F_{\beta}=\left(1+\beta^{2}\right) \cdot \frac{\text { precision } \cdot \text {recall}}{\left(\beta^{2} \cdot \text { precision }\right)+\text {recall}}
$$
常用的如F2和F0.5。
# ROC曲线与AUC值
x轴是FP/（FP+TN），即x轴是预测为正类中样本中真负例占所有真负例样本的比例。y轴是TP/（TP+FN），即y轴是预测为正类样本中的真正例占所有真正例的比例，也就是正例的召回率。
ROC曲线有个很好的特性，当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。
AUC值就是ROC曲线与x轴和y轴组成的封闭曲线内的面积，介于0和1之间。AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类正样本。
# P-R曲线、精确率与召回率的关系
P-R曲线就是以召回率（recall）为横坐标，精确率（precision）为纵坐标的曲线图。
若一个学习器P-R曲线被另一个学习器的P-R曲线完全"包住",则可断言后者的性能优于前者。如果两个学习器的P-R曲线发生了交叉，如图中的A与B，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器A与B比出个高低。这时一个比较合理的判据是比较P-R曲线截面积的大小（面积大者性能更优），但更常用的是平衡点或者是F1值。平衡点（BEP）是查准率=查全率时的取值，如果这个值较大，则说明学习器的性能较好。或者使用F1值为度量，F1值越大，我们可以认为该学习器的性能较好。
P-R曲线有一个缺点就是会受到正负样本比例的影响。比如当负样本增加10倍后，在racall不变的情况下，必然召回了更多的负样本，所以精确度就会大幅下降，所以PR曲线对正负样本分布比较敏感。
对于不同正负样本比例的测试集，P-R曲线的变化就会非常大，而ROC曲线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。
**举例:**
Hulu提供视频的模糊搜索功能，搜索排序模型返回的Top5的精确率非常高，但在实际使用过程中，用户还是经常找不到想要的视频，特别是一些比较冷门的剧集，这可能是哪个环节出了问题呢？
**在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N个返回结果的Precision值和Recall值来衡量排序模型的性能，即认为模型返回的Top N的结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision TOP N和前N个位置上的召回率Recall TOP N。**
为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本，但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致Recall值降低。
在上面这个例子中，模型返回的Precision TOP5的结果非常好，也就是说排序模型Top5的返回值的质量是很高的。也就是说前5个结果精确率很高。
但是在实际应用过程中，用户为了找一些冷门的视频，往往会寻找排在较靠后位置的结果，甚至翻页去查找目标视频。但根据题目描述，用户经常找不到想要的视频，这说明模型没有把相关的视频都找出来呈现给用户。显然，问题出在召回率上。如果相关结果有100个，即使Precision TOP5达到了100%，Recall也仅仅是5%。
这个时候我们就要用Precision-Recall曲线图。对于上面举例的排序模型来说，其P-R曲线上的一个点代表着在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。我们必须根据我们排序系统的主要任务（保证用户前5个结果为真？或保证用户找冷门视频的精确率?）从Precision-Recall曲线图找出一个平衡精确率和准确率的点，使得两者都能有较好的性能。