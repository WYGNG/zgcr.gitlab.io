---
title: K-Means聚类原理
date: 2019-03-11 15:54:20
tags:
- 机器学习原理推导
categories:
- 机器学习原理推导
mathjax: true
---

# K-Means算法介绍
K-Means算法是一种无监督的聚类算法，其中K表示类别数，Means表示均值。它是一种通过均值对数据点进行聚类的算法。K-Means算法通过预先设定的K值及每个类别的初始质心对相似的数据点进行划分。并通过划分后的均值迭代优化获得最优的聚类结果。
K-Means算法有一个重要的假设：数据之间的相似度可以使用欧氏距离度量（可以使用欧氏距离度量的意思就是欧氏距离越小，两个数据相似度越高），如果不能使用欧氏距离度量，则要先把数据转换到能用欧氏距离度量。
# K-Means算法计算过程
* 首先根据对数据的先验经验或交叉验证选择一个合适的k值；
* 随机选择k个点作为k个簇的起始质心；
* 分别计算剩下的元素到k个簇中心的欧氏距离，将这些元素分别划归到距离最近的簇；
* 根据聚类结果，重新计算k个簇各自的中心点，计算方法是取簇中所有元素各自维度的算术平均值；
* 将k个簇的新中心点距离与原有中心点距离进行比较，如果中心点不再变化/聚类结果不再变化/迭代计算轮次达到最大值，则输出聚类结果，否则回到第3步继续迭代计算。

# K-Means算法损失函数
假设簇划分为（C1,C2,...Ck），则我们的目标是最小化平方误差E:
$$
E=\sum_{i=1}^{k} \sum_{x \in C_{i}}(x-\mu_{i})^{2}
$$
其中μi是簇Ci的均值向量，有时也称为质心:
$$
\mu_{i}=\frac{1}{|C_{i}|} \sum_{x \in C_{i}} x
$$
# 肘部法则寻找最优K值
肘部法则评价K值好坏的标准是SSE:
$$
S S E=\sum_{p \in C_{i}}\left|p-m_{i}\right|^{2}
$$
其中Ci代表第i个簇，p是簇Ci里的样本点，mi是簇的质心。
**肘部法则算法:**
随着聚类数k的增大，样本的划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。当k小于最佳聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE会急剧下降；当k到达最佳聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓。也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的最佳聚类数。
# 轮廓系数法寻找最优K值
某个样本点Xi的轮廓系数:
$$
S=\frac{b-a}{\max (a, b)}
$$
其中a是Xi和同簇的其他样本的平均距离，称为凝聚度。 b是Xi和最近簇中所有样本的平均距离，称之为分离度。
最近簇的定义如下:
$$
C_{j}=\arg \min _{C_{k}} \frac{1}{n} \sum_{p \in C_{k}}\left|p-X_{i}\right|^{2}
$$
其中p是簇Ck中的样本。其实就是用Xi到某个簇所有样本平均距离作为衡量该点到该簇的距离后，选择离Xi最近的一个簇作为最近簇。
**轮廓系数法:**
求出所有样本的轮廓系数后再求平均值就得到平均轮廓系数。平均轮廓系数的取值范围为[-1,1]，且簇内样本的距离越近，簇间样本距离越远，平均轮廓系数越大，聚类效果越好。自然地，平均轮廓系数最大的K便是最佳K值。
**轮廓系数法与肘部法则的比较:**
在实践时我们发现肘部法则的最佳K值和轮廓系数的最佳K值是不一样的，轮廓系数的最佳值小于手肘图的最佳值，原因可能是轮廓系数考虑了分离度b，也就是样本与最近簇中所有样本的平均距离。 
从定义上看，轮廓系数大，不一定是凝聚度a（样本与同簇的其他样本的平均距离）小，而可能是b和a都很大的情况下b相对a大得多。a的数值大，则样本与同簇的其他样本的平均距离就大，簇的紧凑程度就弱，那么簇内样本离质心的距离也大，从而导致SSE较大。因此，虽然轮廓系数引入了分离度b而限制了聚类划分的程度，但是同样会引来最优结果的SSE比较大的问题。
因此，轮廓系数法确定出的最优k值不一定是最优的，有时候还需要根据SSE去辅助选取。如果没有特殊情况的话，建议首先考虑肘部法则。
# K-Means++算法:初始化质心的优化方法
K-Means++算法对K-Means随机初始化质心的方法进行了优化。
**算法如下:**
* 从输入的数据点集合中随机选择一个点作为第一个聚类中心μ1；
* 对于数据集中的每一个点xi，计算它与已选择的聚类中心中最近聚类中心的距离:
$$
D(x_{i})=\arg \min (x_{i}-\mu_{r})^{2}
$$
$$
r=1,2, \ldots k_{s e l e c t e d}
$$
* 选择一个新的数据点作为新的聚类中心，选择的原则是：D（x）较大的点被选取作为聚类中心的概率较大；
* 重复第二、三步直到选择出k个聚类质心；
* 利用这k个质心来作为初始化质心去运行标准的K-Means算法。