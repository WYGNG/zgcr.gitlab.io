---
title: 目标检测模型性能指标mAP的含义解释
date: 2019-05-05 22:28:18
tags:
- 计算机视觉
categories:
- 计算机视觉
mathjax: true
---

# 准确率、精确率、召回率、P-R曲线图、平衡点、F1 score、Fβ

```
真实情况    预测为正        预测为反	
正	       TP（真正例）	 FN（假反例）	
反	       FP（假正例）	 TN（真反例）	
```
## 准确率
$$
Accuracy=\frac{TP+TN}{\text {AllSamples}}
$$
## 精确率
 对正类的精确率公式:
$$
P=\frac{T P}{T P+F P}
$$
即预测为真的样本中有多少实际为真。
## 召回率
对正类的召回率公式:
$$
R=\frac{T P}{T P+F N}
$$
即真实为真的样本中有多少被预测为真。
## P-R曲线图
一般来说，我们希望精确率和召回率同时越高越好，然而精确率和召回率是一对矛盾的度量，一个高时另一个就会偏低。我们可以做出P-R曲线图来表示精确率和召回率的关系。
如果一个学习器的P-R曲线被另一个学习器的P-R曲线包围，则可以断言后面的学习器要好些；如果两个曲线有交叉，一个比较合理的判据是比较两个曲线与x轴和y轴围成的面积的大小，但这个面积不好计算。
## 平衡点
上面说了曲线与x轴和y轴围城的面积不好计算，因此我们就找一个准确率=召回率的值，这个值称为平衡点。
## F1 score
F1是准确率和召回率的调和平均数，即
$$
\frac{1}{F 1}=\frac{1}{2} \times\left(\frac{1}{P}+\frac{1}{R}\right)
$$
可写为
$$
F 1=\frac{2 P R}{P+R}
$$
如果我们对P和R的权重不同，可以将上式稍作变形，得到Fβ公式:
## Fβ
Fβ是准确率和召回率的加权调和平均数，即:
$$
\frac{1}{F_{\beta}}=\frac{1}{1+\beta^{2}} \times\left(\frac{1}{P}+\frac{\beta^{2}}{R}\right)
$$
$$
F_{\beta}=\frac{\left(1+\beta^{2}\right) P R}{\beta^{2} P+R}
$$
# AP的计算方式
AP的计算有两种方式。但首先我们要判断预测样本的预测回归框是否正确。
## 判断预测样本回归框是否正确
我们先判断每一个测试样本测试得到的回归框是否正确。VOC数据集的做法是看每一个样本的预测框是否和真值框重合度（IOU）超过50%，超过就按照正类来判别。如果很多个框都框到同一个物体，那么就算其中一个是对的，其他都是错的。
## AP的第一种计算方式:11Point方法
这种方式是VOC2007数据集中提出的。在上面进行预测框判断之后，对所有测试样本（假设样本是二分类，只有正类和负类），样本id和对应样本是正类的置信度保存到一个文件中。然后我们按照置信度从大到小排序，再给定一个r，对于每一个r，选取样本集合中置信度高于r的所有样本，然后在这部分样本中计算其精确率和召回率。最后的AP就是每一个r下计算得到的精确率的平均值。假如我们选择11个不同的r[0, 0.1, ..., 0.9, 1.0]（即11个置信度阈值），那么AP就定义为在这11个置信度阈值下精确率的平均值，其可以表征整个P-R曲线（曲线下面积）。
## AP的第二种计算方式:MAXIntegral方法
这种方式是VOC2010及之后的数据集采用的计算方式。首先仍然要先进行上面的回归框判断。假设所有N个样本中有M个正例，那么我们会得到M个recall值（1/M, 2/M, …, M/M），对于每个recall值r，该recall阈值时top-n所对应的最大精确率，然后对这M个最大精确率值取平均即得到最后的AP值。
**为什么会有最大精确率？**
因为我们上面进行的召回率和精确率的计算，是以一张图片为单位进行的（一张图片上一个类物体可能有多个目标）。那么每一张图上对于每一个召回率都有一个精确率，这样我们就有最大精确率。
## COCO数据集中AP的计算方式
VOC2007/2010数据集在判断预测样本回归框是否正确时用的是IOU>0.5即认为是正样本，但是COCO数据集要求IOU阈值在[0.5, 0.95]区间内每隔0.05取一个值，这样就可以计算出10个类似于VOC数据集中的AP，然后这10个值求平均值即为最后的AP。许多论文中的写法是AP@[0.5:0.95]。
# mAP的计算方式
对于各个类别，分别按照上述方式计算AP，取所有类别的AP平均值就是mAP。简单来说，AP衡量的是模型在某一个类上的性能，而mAP衡量的是模型在所有类别上的性能。
# VOC2007/2010中的AP计算源码解析
```python
import numpy as np


def voc_ap(self, rec, prec, use_07_metric=False):
	# use_07_metric=True表示用voc2007数据集中计算ap的方式
	if use_07_metric:
		ap = 0.
		# voc2007数据集取11个置信度阈值(0., 0.1, 0.2, …, 0.9, 1.0)过滤按置信度排序好的样本
		# 然后分别计算这11个置信度阈值下的精确率，最后取平均值就是ap
		for t in np.arange(0., 1.1, 0.1):
			if np.sum(rec >= t) == 0:
				p = 0
			else:
				# 精确率的计算,是以一张图片为单位进行的,我们总是取某个置信度阈值下的最大精确率
				p = np.max(prec[rec >= t])
			ap = ap + p / 11.
	else:
		# VOC2010及之后的数据集计算AP的方式是取所有不同的recall对应的点处的精度值做平均
		mrec = np.concatenate(([0.], rec, [1.]))
		mpre = np.concatenate(([0.], prec, [0.]))

		# 计算包络线，从后往前取最大保证precise非减
		for i in range(mpre.size - 1, 0, -1):
			mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])

		# 找出所有检测结果中recall不同的点
		i = np.where(mrec[1:] != mrec[:-1])[0]

		# 用recall的间隔对精确率作加权平均
		ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])
	return ap
```