---
title: 目标检测模型性能指标mAP的含义解释
date: 2019-05-05 22:28:18
tags:
- 计算机视觉
categories:
- 计算机视觉
mathjax: true
---

# 准确率、精确率、召回率、P-R曲线图、平衡点、F1 score、Fβ
```
真实情况    预测为正        预测为反	
正	       TP（真正例）	 FN（假反例）	
反	       FP（假正例）	 TN（真反例）	
```
**准确率公式:**
$$
Accuracy=\frac{TP+TN}{\text {AllSamples}}
$$
**对正类的精确率公式:**
$$
P=\frac{T P}{T P+F P}
$$
即预测为真的样本中有多少实际为真。
**对正类的召回率公式:**
$$
R=\frac{T P}{T P+F N}
$$
即真实为真的样本中有多少被预测为真。
**P-R曲线图:**
一般来说，我们希望上述两个指标同时越高越好，然而精确率和召回率是一对矛盾的度量，一个高时另一个就会偏低。我们可以做出P-R曲线图来表示精确率和召回率的关系。
如果一个学习器的P-R曲线被另一个学习器的P-R曲线包围，则可以断言后面的学习器要好些；如果两个曲线有交叉，一个比较合理的判据是比较两个曲线与x轴和y轴围成的面积的大小，但这个面积不好计算。
**平衡点:**
上面说了曲线与x轴和y轴围城的面积不好计算，因此我们就找一个准确率=召回率的值，这个值称为平衡点。
**F1 score:**
F1是准确率和召回率的调和平均数，即
$$
\frac{1}{F 1}=\frac{1}{2} \times\left(\frac{1}{P}+\frac{1}{R}\right)
$$
可写为
$$
F 1=\frac{2 P R}{P+R}
$$
如果我们对P和R的权重不同，可以将上式稍作变形，得到Fβ公式:
**Fβ:**
Fβ是准确率和召回率的加权调和平均数，即:
$$
\frac{1}{F_{\beta}}=\frac{1}{1+\beta^{2}} \times\left(\frac{1}{P}+\frac{\beta^{2}}{R}\right)
$$
$$
F_{\beta}=\frac{\left(1+\beta^{2}\right) P R}{\beta^{2} P+R}
$$
# AP与mAP
在目标检测模型训练时，所使用的数据集中图片的标签往往不止一类，因此，评价模型性能不能用普通单标签图像分类的标准，而采用mAP（mean Average Precision）。
**AP:**
用训练好的模型得到所有测试样本（假设只有一个类别）的置信度，样本id和对应置信度保存到一个文件中。然后我们按照置信度从大到小排序，再给定一个r，精确率和召回率仅在高于r的置信度预测结果中计算，改变r会改变召回率。假如我们选择11个不同的召回率[0, 0.1, ..., 0.9, 1.0]，可以认为是选择了11个r，按照置信度排序，所以实际上等于选择了11个不同的置信度阈值。那么，AP就定义为在这11个召回率下精确率的平均值，其可以表征整个P-R曲线（曲线下面积）。
**mAP:**
对于各个类别，分别按照上述方式计算AP，取所有类别的AP平均值就是mAP。
简单来说，AP衡量的是模型在某一个类上的性能，而mAP衡量的是模型在所有类别上的性能。

需要注意的是，VOC2007数据集提出的mAP计算方法近使用11个召回率值来计算AP，而VOC2010及之后的数据集采用了一种新的计算方法:假设这N个样本中有M个正例，那么我们会得到M个recall值（1/M, 2/M, …, M/M）,对于每个recall值r，我们可以计算出对应（r’ > r）的最大精确率，然后对这M个精确率值取平均即得到最后的AP值。